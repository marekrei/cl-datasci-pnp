{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (sample solution) 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Dataset\n",
    "\n",
    "Bike sharing data – look into the dataset description in the README file.\n",
    "\n",
    "## Step 1: Uploading and inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_data(bike_path):\n",
    "    csv_path = os.path.join(bike_path, \"bike_hour.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data = load_data(\"bike_sharing/\")\n",
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data[\"season\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_data = bike_data.drop(\"instant\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "#so that the plot will be displayed in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bike_data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Summary**: the data was collected in a very balanced way, so attributes like *season*, *yr*, *weekday*, *mnth*, *hour* are represented evenly. Features like *casual* and *registered* are tail-heavy. Feature *season* is categorical so will require converting to numerical values. No missing values in this dataset.\n",
    "\n",
    "## Step 2: Splitting the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "def split_train_test(data, test_ratio):    \n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "train_set, test_set = split_train_test(bike_data, 0.2)\n",
    "print(len(train_set), \"training instances +\", len(test_set), \"test instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(bike_data, test_size=0.2, random_state=42)\n",
    "print(len(train_set), \"training instances +\", len(test_set), \"test instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data[\"hr\"].hist(bins=48)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(bike_data, bike_data[\"hr\"]):\n",
    "    strat_train_set = bike_data.loc[train_index]\n",
    "    strat_test_set = bike_data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_proportions(data):\n",
    "    return data[\"hr\"].value_counts() / len(data)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": hourly_proportions(bike_data),\n",
    "    \"Stratified tr\": hourly_proportions(strat_train_set),\n",
    "    \"Random tr\": hourly_proportions(train_set),\n",
    "    \"Stratified ts\": hourly_proportions(strat_test_set),\n",
    "    \"Random ts\": hourly_proportions(test_set),\n",
    "})\n",
    "compare_props[\"Rand. tr %error\"] = 100 * compare_props[\"Random tr\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Rand. ts %error\"] = 100 * compare_props[\"Random ts\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. tr %error\"] = 100 * compare_props[\"Stratified tr\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. ts %error\"] = 100 * compare_props[\"Stratified ts\"] / compare_props[\"Overall\"] - 100\n",
    "\n",
    "compare_props.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploring the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_data = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind='scatter', x='mnth', y='temp', alpha=0.5,\n",
    "            s=bike_data[\"registered\"]/10, label=\"registered\", figsize=(10,7), \n",
    "            c=bike_data[\"cnt\"], cmap=plt.get_cmap(\"jet\"), colorbar=\"True\",\n",
    "            )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind='scatter', x='mnth', y='atemp', alpha=0.5,\n",
    "            s=(bike_data[\"registered\"] + bike_data[\"casual\"])/10, label=\"all_users\", figsize=(10,7), \n",
    "            c=bike_data[\"cnt\"], cmap=plt.get_cmap(\"jet\"), colorbar=\"True\",\n",
    "            )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind='scatter', x='mnth', y='hr', alpha=0.5,\n",
    "            s=(bike_data[\"registered\"] + bike_data[\"casual\"])/10, label=\"all_users\", figsize=(10,7), \n",
    "            c=bike_data[\"cnt\"], cmap=plt.get_cmap(\"jet\"), colorbar=\"True\",\n",
    "            )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind='scatter', x='weekday', y='hr', alpha=0.5,\n",
    "            s=(bike_data[\"registered\"] + bike_data[\"casual\"])/10, label=\"all_users\", figsize=(10,7), \n",
    "            c=bike_data[\"cnt\"], cmap=plt.get_cmap(\"jet\"), colorbar=\"True\",\n",
    "            )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind='scatter', x='hum', y='atemp', alpha=0.5,\n",
    "            s=(bike_data[\"registered\"] + bike_data[\"casual\"])/10, label=\"all_users\", figsize=(10,7), \n",
    "            c=bike_data[\"cnt\"], cmap=plt.get_cmap(\"jet\"), colorbar=\"True\",\n",
    "            )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind='scatter', x='weathersit', y='atemp', alpha=0.5,\n",
    "            s=(bike_data[\"registered\"] + bike_data[\"casual\"])/10, label=\"all_users\", figsize=(10,7), \n",
    "            c=bike_data[\"cnt\"], cmap=plt.get_cmap(\"jet\"), colorbar=\"True\",\n",
    "            )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = bike_data.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"cnt\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"cnt\", \"registered\", \"casual\", \"temp\", \"atemp\", \"yr\", \"mnth\", \"hum\"]\n",
    "scatter_matrix(bike_data[attributes], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind=\"scatter\", x=\"cnt\", y=\"registered\", alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.plot(kind=\"scatter\", x=\"cnt\", y=\"temp\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bike_data[\"temp_to_hum\"] = bike_data[\"temp\"] / bike_data[\"hum\"]\n",
    "# bike_data[\"atemp_to_hum\"] = bike_data[\"atemp\"] / bike_data[\"hum\"]\n",
    "\n",
    "# to avoid division by zero\n",
    "bike_data[\"temp_to_hum\"] = np.where(bike_data[\"hum\"] == 0, bike_data[\"temp\"] / 0.1, \n",
    "                                    bike_data[\"temp\"] / bike_data[\"hum\"])\n",
    "bike_data[\"atemp_to_hum\"] = np.where(bike_data[\"hum\"] == 0, bike_data[\"atemp\"] / 0.1, \n",
    "                                    bike_data[\"atemp\"] / bike_data[\"hum\"])\n",
    "\n",
    "bike_data[\"casual\"].where(bike_data[\"casual\"] > 0, 0.1, inplace = True)\n",
    "bike_data[\"casual_log\"] = np.log(bike_data[\"casual\"])\n",
    "\n",
    "corr_matrix = bike_data.corr()\n",
    "corr_matrix[\"cnt\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**: the scatter plots show that there is a particular ranges of temperature values leading to a higher count of rented bikes (subject to the month, so less over the winter months). The number of rented bikes is higher around 8am and 5-6pm. Regarding the months, the maximum number of rentals fall within March-October interval, regarding the days of the week – the interval between Tuesday and Saturday (surprisingly, not Monday!). There is a particular cluster of humidity-vs-temperature values that result in higher rental counts. There are a number of attributes highly correlated with the number of rented bikes: among them, *registered* and *casual* most strongly positively correlated, *temp* / *atemp*, *hr* and *yr* strongly positively correlated, *hum* strongly negatively correlated. This can be seen in both correlation values and scatter plots. One might consider using log on registered and casual users, and a combined attribute that reflects the relation between temperature and humidity (e.g., something like a ratio of the temperature value to humidity).\n",
    "\n",
    "\n",
    "## Step 4: Data preparation and transformations for machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_data = strat_train_set.drop(\"cnt\", axis=1).drop(\"dteday\", axis=1)\n",
    "bike_labels = strat_train_set[\"cnt\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(data):\n",
    "    # add the transformed features that you found useful before\n",
    "    data[\"temp_to_hum\"] = np.where(data[\"hum\"] == 0, data[\"temp\"] / 0.1, data[\"temp\"] / data[\"hum\"])\n",
    "    data[\"atemp_to_hum\"] = np.where(data[\"hum\"] == 0, data[\"atemp\"] / 0.1, data[\"atemp\"] / data[\"hum\"])\n",
    "                                            \n",
    "    data[\"casual\"].where(data[\"casual\"] > 0, 0.1, inplace = True)\n",
    "    data[\"casual_log\"] = np.log(data[\"casual\"])\n",
    "\n",
    "add_features(bike_data)\n",
    "bike_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "bike_cat_encoded = encoder.fit_transform(bike_data[\"season\"])\n",
    "bike_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "bike_cat_1hot = encoder.fit_transform(bike_data[\"season\"])\n",
    "bike_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin # TransformerMixin allows you to use fit_transform method\n",
    "\n",
    "class CustomLabelBinarizer(TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, x, y=0):\n",
    "        self.encoder.fit(x)\n",
    "        return self\n",
    "    def transform(self, x, y=0):\n",
    "        return self.encoder.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "bike_num = bike_data.drop(\"season\", axis=1)\n",
    "num_attribs = list(bike_num)\n",
    "cat_attribs = [\"season\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('label_binarizer', CustomLabelBinarizer()),\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "bike_prepared = full_pipeline.fit_transform(bike_data)\n",
    "print(bike_prepared.shape)\n",
    "bike_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implementation, evaluation and fine-tuning of a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(bike_prepared, bike_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = bike_data.iloc[:5]\n",
    "some_labels = bike_labels.iloc[:5]\n",
    "# note the use of transform, as you'd like to apply already learned (fitted) transformations to the data\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\", list(lin_reg.predict(some_data_prepared)))\n",
    "print(\"Actual labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "bike_predictions = lin_reg.predict(bike_prepared)\n",
    "lin_mse = mean_squared_error(bike_labels, bike_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
    "                  ('linear', LinearRegression())])\n",
    "\n",
    "model = model.fit(bike_prepared, bike_labels)\n",
    "bike_predictions = model.predict(bike_prepared)\n",
    "lin_mse = mean_squared_error(bike_labels, bike_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg = tree_reg.fit(bike_prepared, bike_labels)\n",
    "bike_predictions = tree_reg.predict(bike_prepared)\n",
    "tree_mse = mean_squared_error(bike_labels, bike_predictions)\n",
    "tree_mse = np.sqrt(tree_mse)\n",
    "tree_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "def analyse_cv(model):   \n",
    "    scores = cross_val_score(model, bike_prepared, bike_labels,\n",
    "                             scoring = \"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "    # cross-validation expects utility function (greater is better)\n",
    "    # rather than cost function (lower is better), so the scores returned\n",
    "    # are negative as they are the opposite of MSE\n",
    "    sqrt_scores = np.sqrt(-scores) \n",
    "    print(\"Scores:\", sqrt_scores)\n",
    "    print(\"Mean:\", sqrt_scores.mean())\n",
    "    print(\"Standard deviation:\", sqrt_scores.std())\n",
    "    \n",
    "analyse_cv(tree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_cv(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "analyse_cv(forest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# specify the range of hyperparameter values for the grid search to try out \n",
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [4, 8, 16, 20]}]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring=\"neg_mean_squared_error\")\n",
    "grid_search.fit(bike_prepared, bike_labels)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = grid_search.cv_results_\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "cat_one_hot_attribs = ['FALL', 'SPRING', 'SUMMER', 'WINTER']\n",
    "attributes = num_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_feature_importances = lin_reg.coef_\n",
    "sorted(zip(lin_feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = strat_test_set.drop(\"cnt\", axis=1).drop(\"dteday\", axis=1)\n",
    "y_test = strat_test_set[\"cnt\"].copy()\n",
    "add_features(X_test)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "final_model = grid_search.best_estimator_\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = lin_reg\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Summary**: unlike the task described in the practical, this task is very well solved with simple linear regression (more attributes express linear correlation with the target value). The best results are achieved with a linear regression rather than more complex models. The most informative features across the models and correlation analysis include the number of registered and casual users, year, working day, temperature and the ratio of temperature (especially atemp value) to humidity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
